{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0ba5dc-8267-4664-9e49-f91b1888bf58",
   "metadata": {},
   "source": [
    "### Install Python Dependencies\n",
    "\n",
    "**Note: After running this cell, ensure you restart the kernel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf5018-3c61-4f92-a03d-d553db966e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain==0.1.4\n",
    "!pip install -q langchain-community==0.0.16\n",
    "!pip install -q transformers\n",
    "!pip install -q pymilvus\n",
    "!pip install -q transformers\n",
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b22c3-c09b-4bec-93fa-65b62ffa91f1",
   "metadata": {},
   "source": [
    "### Import Python Modules\n",
    "\n",
    "Import the required Python modules from Langchain.\n",
    "\n",
    "* **RecursiveCharacterTextSplitter** - Text splitter. This is required to split our Nutanix Bible content into chunks.\n",
    "* **HuggingFaceEmbeddings** - This allows access to embedding models in Hugging Face\n",
    "* **Milvus** - This allows the code to use and manage our Milvus Vector DB.\n",
    "* **WebBaseLoader** - This loads HTML content into a document format we can use with our DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b5648-3639-46a5-814c-f91d74b8f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deba426-0bf0-4f7d-ab41-89030470200a",
   "metadata": {},
   "source": [
    "### Initialize an instance of HuggingFaceEmbeddings\n",
    "\n",
    "This code is initializing an instance of [HuggingFaceEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.huggingface.HuggingFaceEmbeddings.html) from Langchain, which allows us to access the [Sentence Transformers](https://huggingface.co/sentence-transformers) embedding models in Hugging Face.\n",
    "\n",
    "An embedding is a numerical representation of objects for use in machine learning systems. The text content from the Nutanix Bible needs to be translated into multi-dimensional vectors. Like the foundational models that can be used for chatbots (e.g. LLama2), there are many pre-trained embedding models to help us do this translation. These models have learned from a huge amount of text to understand how words are normally used and in what contexts those words are used in.\n",
    "\n",
    "In this lab, we are using the [sentence-transformers/all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) embedding model.\n",
    "\n",
    "#### Note\n",
    "When running this code, you can ignore the following warning:\n",
    "\n",
    "```\n",
    "/home/jovyan/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99dcc5a-8da1-4451-a88e-7cc74d304125",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "model_kwargs = {}\n",
    "\n",
    "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs # Pass the encoding options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4611efc3-362e-4b4c-b8f6-16bfb1ac4160",
   "metadata": {},
   "source": [
    "### Experiment with Embedding Calculations\n",
    "\n",
    "The following code demonstrates how the embedding model works. This code embeds the text “pear” into a 768-dimensional vector. If you were to remove the [:3], it would print out all 768 elements of the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84628b9-b06d-497a-9405-2efa22c34a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = embeddings.embed_query(\"pear\")\n",
    "print(len(example))\n",
    "print(example[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd961ade-9036-4bf7-a9c3-172b3c9f5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = embeddings.embed_query(\"banana\")\n",
    "print(example[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d27531-35fa-4bc7-a667-82c1b8a8ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = embeddings.embed_query(\"computer\")\n",
    "print(example[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736a6a15-169c-47cf-96c5-4fa1b8530381",
   "metadata": {},
   "source": [
    "### Experiment with Distance Calculations\n",
    "\n",
    "The following code demonstrates how the distance can be calculated between two vectors. A lower score means a shorter distance (i.e., higher relation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ebf9c-77c4-48d8-8c3a-c1c39c7dbcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "evaluator = load_evaluator(\"embedding_distance\", embeddings=embeddings)\n",
    "\n",
    "evaluator.evaluate_strings(prediction=\"apple\", reference=\"pear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30084339-ac7e-4e88-a11f-6e1e9be17091",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate_strings(prediction=\"pear\", reference=\"computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086fde2-5983-4b78-b2e7-5874c7830a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate_strings(prediction=\"banana\", reference=\"computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f394d9-f016-4f7e-be88-9f0c6afad4a1",
   "metadata": {},
   "source": [
    "### Load the Nutanix Bible content\n",
    "\n",
    "This code uses the <a href=\"https://python.langchain.com/docs/integrations/document_loaders/web_base\" target=\"_blank\">WebBaseLoader</a> component of Langchain to load our Nutanix Bible content into a document format that can be ingested into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1b630-2c32-47b9-9f8f-397dca2a5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://www.nutanixbible.com/classic\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2c1f9-7250-4e8f-b3e0-3d87c5b580ea",
   "metadata": {},
   "source": [
    "### Optional - Print Contents\n",
    "\n",
    "The `data` object is a Python list with 1 element. If you uncomment the following cell, it will print out the Document object that contains the entire contents of the Nutanix Bible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525d408-49ed-4bdf-be4f-44e823832099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79fab1b-820e-472e-99f9-909f0bfb01ff",
   "metadata": {},
   "source": [
    "### Split contents of the data object\n",
    "\n",
    "We don’t want to store the data as one vector. In this code, we’ll split up the data into chunks of 500 characters each with the [RecursiveCharacterTextSplitter](https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html) component of Langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55121404-05fe-453c-9291-3dbe0771a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc0cb6d-4a09-416d-bfe2-d5a2bf3a4fd0",
   "metadata": {},
   "source": [
    "### Check length of docs array\n",
    "\n",
    "All of our chunks are stored in array. We can see how many chunks (documents) there are with following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446dbef4-3217-41e9-a71c-91502b8cca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24a8f0-335f-49fe-92b2-c7ce7efa037f",
   "metadata": {},
   "source": [
    "### Optional - View one of the document's contents\n",
    "\n",
    "Feel free to look at different elements by adjusting the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e7a2e5-cd70-4604-b1bc-3d04b499e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[10].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e9d49-4f5f-4fe4-98de-2f9383e7d618",
   "metadata": {},
   "source": [
    "### Ingest the documents into Milvus\n",
    "\n",
    "In this code, we'll ingest our documents into Milvus along with our embeddings object, which will ingest all of our documents and create a vector embedding of each.\n",
    "\n",
    "Note that we are using the internal name of the database service instead of an IP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b97617-3de0-4c10-b38a-c3a4e74e2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = Milvus.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    collection_name=\"nutanixbible_web\",\n",
    "    connection_args={\"host\":\"milvus-vectordb.milvus.svc.cluster.local\",\"port\":\"19530\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108fd52c-b0ca-418e-8522-b0af57841b85",
   "metadata": {},
   "source": [
    "### Search for similar content in the database\n",
    "\n",
    "Now that we've ingested our data, we can search it using the [similarity_search()](https://python.langchain.com/docs/modules/data_connection/vectorstores/#similarity-search) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9393a-385e-45cd-b535-a904264d4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Nutanix Kubernetes Engine?\"\n",
    "result_docs = vector_db.similarity_search(question)\n",
    "print(result_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000aadb6-84f3-4dd8-bf6e-ec917e510e75",
   "metadata": {},
   "source": [
    "### Return to the Lab Guide\n",
    "\n",
    "Move onto the **View Documents in Milvus** section of the lab guide."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
